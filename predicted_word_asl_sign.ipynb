{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n",
      "Image: img/asl_dataset/t/hand1_t_bot_seg_1_cropped.jpeg, Predicted class: t\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Image: img/asl_dataset/h/hand1_h_bot_seg_1_cropped.jpeg, Predicted class: h\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Image: img/asl_dataset/a/hand1_a_bot_seg_1_cropped.jpeg, Predicted class: a\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Image: img/asl_dataset/n/hand1_n_bot_seg_2_cropped.jpeg, Predicted class: n\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Image: img/asl_dataset/k/hand1_k_bot_seg_2_cropped.jpeg, Predicted class: k\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Image: img/asl_dataset/x/hand1_x_bot_seg_2_cropped.jpeg, Predicted class: x\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Image: outputfolder/frame_1.jpg, Predicted class: p\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Image: outputfolder/frame_31.jpg, Predicted class: c\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Image: outputfolder/frame_61.jpg, Predicted class: c\n",
      "Predicted word: thankxpcc\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'label_dict' is already defined\n",
    "label_dict = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "               10: 'a', 11: 'b', 12: 'c', 13: 'd', 14: 'e', 15: 'f', 16: 'g', 17: 'h', 18: 'i',\n",
    "                 19: 'j', 20: 'k', 21: 'l', 22: 'm', 23: 'n', 24: 'o', 25: 'p', 26: 'q', 27: 'r',\n",
    "                   28: 's', 29: 't', 30: 'u', 31: 'v', 32: 'w', 33: 'x', 34: 'y', 35: 'z'}\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image_size = 200\n",
    "# Path to your trained model\n",
    "model_path = 'model_asl_2.h5'\n",
    "\n",
    "# Load the model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# List of image paths\n",
    "image_paths = ['img/asl_dataset/t/hand1_t_bot_seg_1_cropped.jpeg',\n",
    "              'img/asl_dataset/h/hand1_h_bot_seg_1_cropped.jpeg',\n",
    "              'img/asl_dataset/a/hand1_a_bot_seg_1_cropped.jpeg',\n",
    "              'img/asl_dataset/n/hand1_n_bot_seg_2_cropped.jpeg',\n",
    "              'img/asl_dataset/k/hand1_k_bot_seg_2_cropped.jpeg',\n",
    "              'img/asl_dataset/x/hand1_x_bot_seg_2_cropped.jpeg',\n",
    "              'outputfolder/frame_1.jpg',\n",
    "              'outputfolder/frame_31.jpg',\n",
    "              'outputfolder/frame_61.jpg',\n",
    "              \n",
    "               # Add more image paths as needed\n",
    "              ]\n",
    "\n",
    "# List to store the predicted class labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Loop through the list of image paths and make predictions\n",
    "for image_path in image_paths:\n",
    "    # Preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(image_size, image_size))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  # Normalize the pixel values\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "    # Map the predicted class index to the corresponding class label\n",
    "    predicted_class_label = label_dict[predicted_class_index]\n",
    "\n",
    "    # Append the predicted class label to the list\n",
    "    predicted_labels.append(predicted_class_label)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Image: {image_path}, Predicted class: {predicted_class_label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # Print predicted letters\n",
    "    \n",
    "\n",
    "# Join the predicted labels to form the final predicted word\n",
    "predicted_word = ''.join(predicted_labels)\n",
    "\n",
    "# Print the final predicted word\n",
    "print(f\"Predicted word: {predicted_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.00 seconds, Frame: 1\n",
      "Time: 1.00 seconds, Frame: 31\n",
      "Time: 2.00 seconds, Frame: 61\n",
      "Frames extracted successfully at outputfolder\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to extract frames from a video with a specified frame rate\n",
    "def extract_frames(video_path, output_folder, frame_rate=1):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get the frames per second (fps) and total number of frames\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Calculate the frame interval based on the desired frame rate\n",
    "    frame_interval = int(fps / frame_rate)\n",
    "\n",
    "    # Loop through frames with the specified interval and save them as images\n",
    "    for frame_number in range(0, total_frames, frame_interval):\n",
    "        # Set the frame position to the current frame number\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Break the loop if we have reached the end of the video\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Calculate the time in seconds for the current frame\n",
    "        seconds = frame_number / fps\n",
    "\n",
    "        # Save the frame as an image\n",
    "        frame_filename = os.path.join(output_folder, f\"frame_{frame_number + 1}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "        # Print the time in seconds and corresponding frame number\n",
    "        print(f\"Time: {seconds:.2f} seconds, Frame: {frame_number + 1}\")\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Frames extracted successfully at {output_folder}\")\n",
    "\n",
    "# Example usage\n",
    "video_path = \"img/WhatsApp Video 2024-01-17 at 15.50.38_7fc72406.mp4\"\n",
    "output_folder = \"outputfolder\"\n",
    "extract_frames(video_path, output_folder, frame_rate=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
